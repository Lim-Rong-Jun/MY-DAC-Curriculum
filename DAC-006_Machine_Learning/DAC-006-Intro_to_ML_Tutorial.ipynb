{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will be creating a classifcation model. The data were collected from the Taiwan Economic Journal for the years 1999 to 2009. Company bankruptcy was defined based on the business regulations of the Taiwan Stock Exchange. Apply what you have learnt and come up with the optimal model to predict if a company goes bankrupt or not. \n",
    "\n",
    "Bonus: Determine what are the key features that influence your model. \n",
    "\n",
    " PS: If you find a technique/method that you believe was not shared in class but useful; you can and should use it. No points will be deducted for trying! Do not delete your trial scripts, these will be important for you to understand where you improved from your previous attempts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given your model score, why did you choose a specific model to present to us? is it cuz of the precision score? accuracy score? t score? to this score/f1 score? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, r2_score, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core ratios for Z-score calculation\n",
    "df['Z_score'] = (\n",
    "    1.2 * df[' Working Capital to Total Assets'] +\n",
    "    1.4 * df[' Retained Earnings to Total Assets'] +\n",
    "    3.3 * df[' Net Income to Total Assets'] +  # Approximation for EBIT/Total Assets\n",
    "    0.6 * df[' Net worth/Assets'] +  # Substitute for Market Value of Equity/Book Liabilities\n",
    "    1.0 * df[' Revenue Per Share (Yuan 짜)'] / df[' Total Asset Growth Rate']  # Scaled for Sales/Total Assets\n",
    ")\n",
    "\n",
    "# Target variable: Bankrupt? (1 = bankrupt, 0 = not bankrupt)\n",
    "x = df[['Z_score', ' Debt ratio %', ' Cash Flow to Total Assets', \" Net Income to Stockholder's Equity\"]]\n",
    "y = df['Bankrupt?']\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores for each feature\n",
    "z_scores = np.abs(zscore(df[['Z_score', ' Debt ratio %', ' Cash Flow to Total Assets', \" Net Income to Stockholder's Equity\"]]))\n",
    "\n",
    "# Set a threshold (e.g., 3 standard deviations)\n",
    "outliers = (z_scores > 3)\n",
    "\n",
    "# Print outliers indices\n",
    "print(np.where(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN or Inf values in your dataset\n",
    "print(df.isna().sum())  # Check for NaN values\n",
    "print(np.isinf(df).sum())  # Check for Inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with column mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Replace zero values with a small non-zero value (e.g., a small epsilon)\n",
    "df[[' Working Capital to Total Assets', ' Retained Earnings to Total Assets', ' Net Income to Total Assets',\n",
    "    ' Net worth/Assets', ' Revenue Per Share (Yuan 짜)', ' Total Asset Growth Rate']] = df[\n",
    "    [' Working Capital to Total Assets', ' Retained Earnings to Total Assets', ' Net Income to Total Assets',\n",
    "     ' Net worth/Assets', ' Revenue Per Share (Yuan 짜)', ' Total Asset Growth Rate']].replace(0, 1e-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core ratios for Z-score calculation\n",
    "df['Z_score'] = (\n",
    "    1.2 * df[' Working Capital to Total Assets'] +\n",
    "    1.4 * df[' Retained Earnings to Total Assets'] +\n",
    "    3.3 * df[' Net Income to Total Assets'] +  # Approximation for EBIT/Total Assets\n",
    "    0.6 * df[' Net worth/Assets'] +  # Substitute for Market Value of Equity/Book Liabilities\n",
    "    1.0 * df[' Revenue Per Share (Yuan 짜)'] / df[' Total Asset Growth Rate']  # Scaled for Sales/Total Assets\n",
    ")\n",
    "\n",
    "# Target variable: Bankrupt? (1 = bankrupt, 0 = not bankrupt)\n",
    "x = df[['Z_score', ' Debt ratio %', ' Cash Flow to Total Assets', \" Net Income to Stockholder's Equity\"]]\n",
    "y = df['Bankrupt?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Inf values in the Z-score column\n",
    "print(np.isinf(df['Z_score']).sum())\n",
    "\n",
    "# Optionally, clip values that are still too large (if desired)\n",
    "df['Z_score'] = np.clip(df['Z_score'], -1e10, 1e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# regularization constant (strength)\n",
    "REG_CONST = 0.01\n",
    "\n",
    "# Create a model and fit it to the training data.\n",
    "#(l2 -Ridge Regression here)\n",
    "# C := inverse of regularization strength \n",
    "model = LogisticRegression(penalty='l2', C=1./REG_CONST, max_iter=300)\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = best_rf.predict(x_test)\n",
    "y_prob = best_rf.predict_proba(x_test)[:, 1]  # Get probabilities for ROC\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Create and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print AUC score\n",
    "print(f'AUC Score: {roc_auc:.3f}')\n",
    "print(f'F1 Score: {f1:.3f}')\n",
    "\n",
    "# Print Classification Report \n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
